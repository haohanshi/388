{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level of Education Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By Alex Shi, Mark Lee, Jun Ma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is be based on the idea of predicting education level by observing user behavior. More specifically, we plan to analyze the public posts of users on Facebook, using natural language processing to estimate the sophistication of said posts, and correlating the estimations with the actual education level of the users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the libraries that we are going to use:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import json\n",
    "import datetime\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools for streaming data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import facebook\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools for analyzing each user's text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from textanalyzer import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use facebook as our source of information, and we gather a list of users and their information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing source of analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using facebook api:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app_id = \"1786012341650556\"\n",
    "app_secret = \"deaada8ad48ddb190897068758c4d0ae\"\n",
    "access_token = app_id + \"|\" + app_secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geting posts from the source users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user = \"BillGates\"\n",
    "\n",
    "graph = facebook.GraphAPI('EAACEdEose0cBAGayMJ3sP0tPLtGjoTFauQ3qDEj5FKCZAcrki8Gc8rzcNLykloWi6I9AJ0DGNaW26mSJWWVi9xymaCB1en1iXmbNZB7mHg5ZAfJKCpi4sxo4ZBinvNNbjN8HNmI9znJOnww5W0WaY35MbwhQVHA4ekWDG6dltgZDZD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview of how we gathered the data from facebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use my account as an example\n",
    "# getting the list of my friends\n",
    "profile = graph.get_object(\"me\")\n",
    "posts = graph.get_connections(profile['id'], 'friends')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have collected a considerable amound of facebook user data. The raw data are collected by using facebook-sdk libaray and facebook graph api. The file address is given in the code section and is in the tar file of the final project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to be filled with file address\n",
    "fb_data = \"\"\n",
    "\n",
    "# working with the collected data:\n",
    "for line in fb_data:\n",
    "    try:\n",
    "        info = json.loads(line)\n",
    "        data.append(info['user'])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use FleshReadingEase to compute the complexity level of each post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After researching about topics related to natural language processing, we found a suitable algorithm that will aid our analysis. The algorithm is called \"Flesch–Kincaid readability tests\". After we gather the posts from users, we will use it to analyze the complexity level of certain block of text. This will provide a numerical assessment certain user's words. Given a numerical value, it's easier for us to analyze the words can correlate it with other attributes we want to work with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flesh Reading Ease (Flesch–Kincaid readability tests):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overview: \"The Flesch readability score uses the sentence length (number of words per sentence) and the number of syllables per word in an equation to calculate the reading ease. Texts with a very high Flesch reading ease score (about 100) are very easy to read.\" (yoast.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstraction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = 0.0\n",
    "#analyzedVars = self.analyzedVars        \n",
    "#score = 206.835 - (1.015 * (analyzedVars['averageWordsPerSentence'])) - (84.6 * (analyzedVars['syllableCount']/ analyzedVars['wordCount']))\n",
    "#return round(score, 4)e the libraries that we are going to use:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting all data into dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - User's education information from facebook user account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides calculating the readability score of the posts from certain user, we will directly get the education level(if possible) of the user we want to collect test date from. In the someone's Facebook profile, we can see that a user's information is consist of many fields, and one of them is education. This is a very important parameter for our analysis, becuase we will use this information to build our SVM for future prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Predicted (computed) complexity level of that user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averaging the score from the results calculated on every post of each user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first average the score for each user, and put the user's education level from his/her profile and the average score together as input and output parameters. Then we will build an SVM to train a correlation model between those two fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Given the computed complexity, predict the actual education level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we finish building our predicting model, we're able to estimate the education level of certain user. We will create a wrapper that calculates the overall score of a given user by averaging the results of each post, and then apply our prediction model to give an estimate of the user's education level. (uneducated, grade school, middle school, high school, undergraduate, intellectual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
